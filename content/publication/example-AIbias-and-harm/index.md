---
title: "An Assessment of Reported Biases and Harms of Large Language Models"

# Authors
# If you created a profile for a user (e.g. the default `admin` user), write the username (folder name) here 
# and it will be replaced with their full name and linked to their profile.
authors:
- Heesoo Jang
- Jaemin Cho

# Author notes (optional)
# author_notes:
#- "Equal contribution"
#- "Equal contribution"

date: "2024-06-21"
#doi: ""

# Schedule page publish date (NOT publication's date).
#publishDate: "2017-01-01T00:00:00Z"

# Publication type.
# Legend: 0 = Uncategorized; 1 = Conference paper; 2 = Journal article;
# 3 = Preprint / Working Paper; 4 = Report; 5 = Book; 6 = Book section;
# 7 = Thesis; 8 = Patent
publication_types: ["1"]

# Publication name and optional abbreviated publication name.
publication: International Communication Association (ICA) Conference


abstract: Artificial intelligence (AI) systems are perpetuating social biases, harming those who are already marginalized. In response, documenting ethical considerations of AI models has emerged as a non-algorithmic solution to assess and mitigate AI biases and harms. This study examined how biases and harms are reported and understood in the documents of so-called large language models (LLMs). We used both qualitative thematic analysis and quantitative content analysis. Based on our analysis, we discuss the implications of our findings, including the need for public availability for identifying and mitigating biases, the observed consensus around understanding biases in models, bias evaluations that narrowly define bias through existing benchmarks, the need to go beyond just listing harms than discussing them, and delegation of mitigation efforts to future work and downstream applications. Our study shows that the AI industry needs more interdisciplinary collaborations with scholars who have expertise in representation, bias, prejudice, and ethics.

# Summary. An optional shortened abstract.
summary: This study analyzes how biases and harms are reported in large language model documentation, highlighting the need for interdisciplinary collaboration to address ethical issues and improve mitigation efforts in AI. It received the Top Paper Award.

tags: []

# Display this page in the Featured widget?
featured: true

# Custom links (uncomment lines below)
# links:
# - name: Custom Link
#   url: http://example.org

url_pdf: uploads/ICA_ASSESSMENT_BIAS_TITLE.pdf
url_code: ''
url_dataset: ''
url_poster: ''
url_project: ''
url_slides: ''
url_source: ''
url_video: ''

# Featured image
# To use, add an image named `featured.jpg/png` to your page's folder. 
image:
#  caption: 'Image credit: [**Unsplash**](https://unsplash.com/photos/pLCdAaMFLTE)'
  focal_point: ""
  preview_only: false

# Associated Projects (optional).
#   Associate this publication with one or more of your projects.
#   Simply enter your project's folder or file name without extension.
#   E.g. `internal-project` references `content/project/internal-project/index.md`.
#   Otherwise, set `projects: []`.
projects: []

# Slides (optional).
#   Associate this publication with Markdown slides.
#   Simply enter your slide deck's filename without extension.
#   E.g. `slides: "example"` references `content/slides/example/index.md`.
#   Otherwise, set `slides: ""`.
slides: ""
---



